{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GermanStanzione/TT-2C2025-Data-Analitycs-Notebooks/blob/main/Clase_3/Mia/Clase_03_NB2_Import_datasets_con_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métodos para importar datasets con Pandas"
      ],
      "metadata": {
        "id": "AtJpnsxspqt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Links que vamos a usar:"
      ],
      "metadata": {
        "id": "SQPoi9uIfUJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [Blog Kaggle - International Hotel Booking Analytics](https://www.kaggle.com/code/sonawanelalitsunil/international-hotel-booking-analytics-ml-34-75/notebook)\n",
        "* [Datasets Kaggle - International Hotel Booking Analytics](https://www.kaggle.com/datasets/alperenmyung/international-hotel-booking-analytics)\n",
        "* [Dataset Github - LifeExpectancy ](https://raw.githubusercontent.com/resbaz/r-novice-gapminder-files/master/data/gapminder-FiveYearData.csv)\n",
        "* [Dataset Kaggle - Netflix](https://www.kaggle.com/datasets/shivamb/netflix-shows/code)"
      ],
      "metadata": {
        "id": "5CDwBA2tpt23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Descargar los datasets (archivos .csv) antes de comenzar"
      ],
      "metadata": {
        "id": "z8RTgLrAwjy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Opción 1:\n",
        "Decargarlos desde el Repositorio Oficial del Curso [Click Aquí](https://drive.google.com/drive/folders/1LI3HcSqcrSJ52YZAoQG0NNmdOnHVSJHG)\n",
        "* Opción 2:\n",
        "Decargarlos desde Kaggle [Click Aquí](https://www.kaggle.com/datasets/alperenmyung/international-hotel-booking-analytics) - Haciendo click en el botón Download/Descargar (Debe descomprimir el archivo \"archive.zip\")"
      ],
      "metadata": {
        "id": "-wNMH1OGhWBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Preparar los archivos en Google Drive"
      ],
      "metadata": {
        "id": "kj6GV85devHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Crear en su unidad de Google Drive la carpeta \"datasets\"\n",
        "2. Subir a esa carpeta los archivos:\n",
        "* hotels.csv\n",
        "* reviews.csv\n",
        "* users.csv"
      ],
      "metadata": {
        "id": "bHoI91tiiyqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Montar y liberar la unidad"
      ],
      "metadata": {
        "id": "FldXXQ72929y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código permite montar la unidad de su Drive en este ambiente virtual de Colab"
      ],
      "metadata": {
        "id": "mkFHp34GjGgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar la unidad\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ALDG9MtAz268"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al finalizar la actividad o en caso que lo requiera, puede desmontar la unidad con este código"
      ],
      "metadata": {
        "id": "7FrKv6kojR4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Liberar la unidad\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "5ZhjulY-8wb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Importar datasets"
      ],
      "metadata": {
        "id": "-Gr5xwCMjjCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación veremos varias opciones para importar datasets a Google Colab usando Pandas, el método dependerá de la necesidad y de sus conocimientos, por ello se plantean varios escenarios para cada nivel."
      ],
      "metadata": {
        "id": "27BIEobVjmNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Importar datasets desde Google Sheets  (Nivel Inicial)"
      ],
      "metadata": {
        "id": "vWgQoVMd0hVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar la librería Pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "M_2t2dgOkFdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Acceso a Gsheets - Metodo con URL de conversion a CSV (lectura)\n",
        "# El archivo debe tener permisos de lectura para TODOS\n",
        "ID_planilla = '1LeWVQ0Pd9XlQ70oTWggueRGLBXISMTGDiLG7wZ6otSI'\n",
        "URL = f'https://docs.google.com/spreadsheets/d/{ID_planilla}/gviz/tq?tqx=out:csv&sheet='\n",
        "df_gs = pd.read_csv(URL + 'ventas')\n",
        "df_gs.head()"
      ],
      "metadata": {
        "id": "BPWfIZPf0iDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Importar datasets desde Google Drive  (Nivel Inicial)\n"
      ],
      "metadata": {
        "id": "QlUQhrm2yces"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta instancia, ya deberías tener creada la carpeta `datasets` en el raíz de tu Unidad de Google Drive, y ahi haber subido los archivos csv que vamos a usar"
      ],
      "metadata": {
        "id": "pAweq7H_QL5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar que los archivos csv se encuentren en la carpeta datasets\n",
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/datasets\")"
      ],
      "metadata": {
        "id": "KHgehMBJQGx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar la librería Pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "9tdTFMOFSd0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar el método read_csv de Pandas (pd) que recibe como argumento el archivo csv y retorna un dataframe\n",
        "df_users = pd.read_csv('/content/drive/MyDrive/datasets/users.csv')\n",
        "df_users.head()"
      ],
      "metadata": {
        "id": "mp6tO9sqQk1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Importar datasets desde Google Drive (Nivel Intermedio)"
      ],
      "metadata": {
        "id": "oRcDT__OQ4pI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si van a trabajar con datasets que se encuentran en diferentes carpetas, puden cambiar la ruta por defecto"
      ],
      "metadata": {
        "id": "j1BXJiltPA5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Se sugiere usar el panel de navegación laterar para explorar las carpetas y sus archivos.\n",
        "2. Cambiar la ruta original al directorio donde se encuentran los archivos .csv que se quieren importar"
      ],
      "metadata": {
        "id": "Z8MPOaF8-LdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validar la ruta y la existencia del archivo csv a importar\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/TT2C2025 - Data Analytics con Python/Repositorio Notebooks de clases/Clase 3/Datasets\")\n",
        "os.listdir(\".\")"
      ],
      "metadata": {
        "id": "2iYzc0hM16_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar la librería Pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "xOSUn5XEUz4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar el método read_csv de Pandas (pd) que recibe como argumento el archivo csv y retorna un dataframe\n",
        "df = pd.read_csv('users.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Q7hYj8kd0HaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Importar datasets desde Github"
      ],
      "metadata": {
        "id": "HNxpXDs_4ESy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar en una variable la URL del archivo csv de Github\n",
        "url = \"https://raw.githubusercontent.com/resbaz/r-novice-gapminder-files/master/data/gapminder-FiveYearData.csv\""
      ],
      "metadata": {
        "id": "gceBkvvkU9U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar la librería Pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "CeJUej9D4R6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar el método read_csv de Pandas (pd) que recibe como argumento el archivo csv y retorna un dataframe\n",
        "df_github = pd.read_csv(url)\n",
        "df_github.head()"
      ],
      "metadata": {
        "id": "jAThz1QOVGt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5 Importar Datasets públicos desde Kaggle (Nivel Avanzado)\n",
        "\n",
        "\n",
        "> Para datasets públicos que no requieren autenticación\n",
        "\n"
      ],
      "metadata": {
        "id": "ZoP6qhipF5zu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando quieran descargar un dataset público desde Kaggle, hacer click en download y pegrn el código \"Download Via kagglehub\"\n",
        "<BR>\n",
        "En este caso vamos a descargar el dataset [Netflix Movies](https://www.kaggle.com/datasets/shivamb/netflix-shows/code)"
      ],
      "metadata": {
        "id": "-bDUYhhMbH0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"shivamb/netflix-shows\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "dtYzg3RjMj9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kagglehub descarga sus archivos en un cache, path informa la ruta.\n",
        "<BR>\n",
        "Lo que hacemos es copiarlo a la carpeta \"datasets\" de nuestro drive"
      ],
      "metadata": {
        "id": "jZubEQ-ibGC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar la unidad\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zp98bNoFaS00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "# Carpeta destino\n",
        "dest_dir = \"/content/drive/MyDrive/datasets/\"\n",
        "\n",
        "# Copiar todos los archivos del dataset al destino\n",
        "for file in os.listdir(path):\n",
        "    shutil.copy(os.path.join(path, file), dest_dir)\n",
        "\n",
        "print(\"Archivos copiados a:\", dest_dir)\n",
        "print(\"Contenido:\", os.listdir(dest_dir))"
      ],
      "metadata": {
        "id": "6x9x8bzdZxdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar el método read_csv de Pandas (pd) que recibe como argumento el archivo csv y retorna un dataframe\n",
        "df = pd.read_csv(f\"{path}/netflix_titles.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "5BiSK3f4M_5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.6 Importar Datasets privados desde Kaggle (Nivel Avanzado)\n",
        "\n",
        "\n",
        "> Para datasets privados que si requieren autenticación"
      ],
      "metadata": {
        "id": "WIA6SNeKcIcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crear una carpeta en el raíz del Drive llamada `kaggle` y pegar el archivo `kaggle.json` (API Token) que generan desde su perfil de Kaggle"
      ],
      "metadata": {
        "id": "6dm-mx94aerh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar la unidad\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BR314at2F8F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validar la existencia del JSON\n",
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/kaggle\")"
      ],
      "metadata": {
        "id": "QDu-IQntIRrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código crear una carpeta kaggle en el raíz y la segunda linea un copy/paste de `kaggle.json`"
      ],
      "metadata": {
        "id": "tTMW5jC_cgv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "3lDWa_cxHepx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso vamos a descargar el mismo dataset [Netflix Movies](https://www.kaggle.com/datasets/shivamb/netflix-shows/code)\n",
        "<BR>\n",
        "Aunque al ser público esto no es necesario\n"
      ],
      "metadata": {
        "id": "xc2jTvBGckic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Este código descarga el dataset con las credenciales\n",
        "!kaggle datasets download -d shivamb/netflix-shows -p /content/drive/MyDrive/datasets\n",
        "!unzip /content/drive/MyDrive/datasets/netflix-shows.zip -d /content/drive/MyDrive/datasets"
      ],
      "metadata": {
        "id": "y5qW5xY7Hvqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validar la existencia del archivo descargado\n",
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/datasets\")"
      ],
      "metadata": {
        "id": "TBcs2fWCdU67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar la librería Pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Jw5mjWQ2WwYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/datasets/netflix_titles.csv\")\n",
        "print(df.shape)   # filas y columnas\n",
        "df.head()         # primeras 5 filas"
      ],
      "metadata": {
        "id": "RH4MLEIUa0EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.7 Importar Datos desde una base de datos relacional ya subida a la carpeta datasets del raíz\n"
      ],
      "metadata": {
        "id": "6YfoTeOd5Uc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta modalidad, deben descargar la carpeta zip desde desde este link\n",
        "<BR>\n",
        "[Descargar](https://www.kaggle.com/datasets/alperenmyung/international-hotel-booking-analytics)\n",
        "<BR>\n",
        "Descomprimir la carpeta y subir el archivo `booking_db.sqlite` a la carpeta `/datasets` de su Drive"
      ],
      "metadata": {
        "id": "_xfHexMA6rR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar la unidad\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vF5wF_IV5emO",
        "outputId": "c96ef281-5ac9-4030-9f2d-ed89cd3fff50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validar la existencia de la DB\n",
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/DataSets\")"
      ],
      "metadata": {
        "id": "vrhgOxBr5hrk",
        "outputId": "c77c65e8-597d-4812-92e2-eaff5faa7158",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Copia de Copia de Kaggle_users.gsheet',\n",
              " 'Copia de Copia de hotels.csv',\n",
              " 'Copia de Copia de reviews.csv',\n",
              " 'users.csv',\n",
              " 'netflix_titles.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerías\n",
        "import sqlite3\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cA8b0ImV5n2v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecemos la conexión a la db\n",
        "conexion = sqlite3.connect('/content/drive/MyDrive/DataSets/booking_db.sqlite')"
      ],
      "metadata": {
        "id": "lgj6yIeh5rNN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_sql('''\n",
        "    SELECT\n",
        "        *\n",
        "    FROM reviews\n",
        "    ;\n",
        "''', conexion, index_col='review_id', parse_dates=['review_date'])"
      ],
      "metadata": {
        "id": "8UPDdkkh5x_v",
        "outputId": "bff8ee20-f34c-42ab-aa1b-189893196600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DatabaseError",
          "evalue": "Execution failed on sql '\n    SELECT\n        *\n    FROM reviews\n    ;\n': no such table: reviews",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: no such table: reviews",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2318576960.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df = pd.read_sql('''\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mSELECT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mFROM\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpandas_sql\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandas_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSQLiteDatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m             return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    707\u001b[0m                 \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2736\u001b[0m         \u001b[0mdtype_backend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDtypeBackend\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m     ) -> DataFrame | Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2739\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Execution failed on sql '{sql}': {exc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2686\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\n    SELECT\n        *\n    FROM reviews\n    ;\n': no such table: reviews"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_sql('''\n",
        "    SELECT\n",
        "    review_id, hotel_name, city, star_rating, score_overall, u.country\n",
        "    FROM hotels h\n",
        "    join reviews r on h.hotel_id = r.hotel_id\n",
        "    join users u on r.user_id = u.user_id\n",
        "    order by score_overall asc\n",
        "    ;\n",
        "''', conexion, index_col='review_id')"
      ],
      "metadata": {
        "id": "UFAio6cf50ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_sql('''\n",
        "    SELECT\n",
        "    review_id, hotel_name, city, avg(score_overall)\n",
        "    FROM hotels h\n",
        "    join reviews r on h.hotel_id = r.hotel_id\n",
        "    group by hotel_name, city\n",
        "    order by avg(score_overall) desc\n",
        "    ;\n",
        "''', conexion, index_col='review_id')"
      ],
      "metadata": {
        "id": "opL36JfF52go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.8 Importar Datos desde una base de datos relacional (usando credenciales de Kaggle - descarga directa)"
      ],
      "metadata": {
        "id": "erUET5-eAtCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar la unidad\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JfS3D0FVGJee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validar la existencia del JSON\n",
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/kaggle\")"
      ],
      "metadata": {
        "id": "uOrBzDC_GKFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una carpeta temporal en el ambiente virtual\n",
        "!mkdir -p ~/.kaggle\n",
        "# ahí pegamos las credenciales\n",
        "!cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/\n",
        "# cambiamos los permisos\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "sduvcr-6G-fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Este código descarga el dataset con las credenciales a la carpeta datasets\n",
        "!kaggle datasets download -d alperenmyung/international-hotel-booking-analytics -p /content/drive/MyDrive/datasets\n",
        "# y con esta línea hacemos el unzip\n",
        "!unzip /content/drive/MyDrive/datasets/international-hotel-booking-analytics.zip -d /content/drive/MyDrive/datasets"
      ],
      "metadata": {
        "id": "-MMj-YXiHEKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerías\n",
        "import sqlite3\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OZiq-AT9IInQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecemos la conexión a la db\n",
        "conexion = sqlite3.connect('/content/drive/MyDrive/datasets/booking_db.sqlite')"
      ],
      "metadata": {
        "id": "ANsHSHCtIR47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_sql('''\n",
        "    SELECT\n",
        "        *\n",
        "    FROM reviews\n",
        "    ;\n",
        "''', conexion, index_col='review_id', parse_dates=['review_date'])"
      ],
      "metadata": {
        "id": "0m19EvEOA0pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_sql('''\n",
        "    SELECT\n",
        "    review_id, hotel_name, city, star_rating, score_overall, u.country\n",
        "    FROM hotels h\n",
        "    join reviews r on h.hotel_id = r.hotel_id\n",
        "    join users u on r.user_id = u.user_id\n",
        "    order by score_overall asc\n",
        "    ;\n",
        "''', conn, index_col='review_id')"
      ],
      "metadata": {
        "id": "qUdYvhlQJ75s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_sql('''\n",
        "    SELECT\n",
        "    review_id, hotel_name, city, avg(score_overall)\n",
        "    FROM hotels h\n",
        "    join reviews r on h.hotel_id = r.hotel_id\n",
        "    group by hotel_name, city\n",
        "    order by avg(score_overall) desc\n",
        "    ;\n",
        "''', conn, index_col='review_id')"
      ],
      "metadata": {
        "id": "RsJMixXATyXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "TbTrLmfo6Z6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "FnzMjnFC6bk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "qUwjXGZN6gmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "jl2Qnw4qI1fS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}